{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GildaRech/test-live-coding/blob/master/Gilda_of_Perceptron_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Please make a copy of the notebook before you start updating it."
      ],
      "metadata": {
        "id": "h0Cu9Drja8Ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and load the data from sklearn dataset"
      ],
      "metadata": {
        "id": "aOJufAT477Vz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VhoY8C6aa5HT"
      },
      "outputs": [],
      "source": [
        " ### Import packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d5HcWRp0a5HX"
      },
      "outputs": [],
      "source": [
        "### Import datasets from sklearn.datasets\n",
        "data = load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "radjgNPta5HX"
      },
      "outputs": [],
      "source": [
        "#### Target \n",
        "\n",
        "target = data.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jNETJucqa5HY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f110f8b1-f1e1-4735-9b98-b9e5f2f4bedd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
              " 'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'data_module': 'sklearn.datasets.data',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'frame': None,\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuA67g7teOmb",
        "outputId": "cc9410cb-bb28-45dc-f3cb-fa9920ae2fe3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b4XAj5Rta5HY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7582da4-844d-4669-c9c2-4aecfa03429f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "### the uniques values\n",
        "\n",
        "N_= np.unique(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRvdDUEra5HY",
        "outputId": "26c08292-ed7e-4c7d-a967-50eb20fdc4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the unique values in the targets are [0 1 2]\n"
          ]
        }
      ],
      "source": [
        "print('the unique values in the targets are', N_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4qtWQzna5HZ",
        "outputId": "7739e0b1-aed1-429a-9e5c-4ec038bfedf7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove the class 2 in our dataset in order to have a binary classification problem"
      ],
      "metadata": {
        "id": "FwLb63ZQ8Spu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gOL6z-Qqa5Ha"
      },
      "outputs": [],
      "source": [
        "##############\n",
        "#y = np.array([i for i in target if i != 2])\n",
        "y=target[target != 2]\n",
        "#######"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QRFOsXyQa5Ha",
        "outputId": "d21a4f07-e951-43ce-d6b8-f7dc84873373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EOcinLHa5Hb",
        "outputId": "f8b9238e-f898-427f-e86f-ef94cdaad884"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replace all 0 in the target by -1 using numpy"
      ],
      "metadata": {
        "id": "yQ_xeoyJ0VWd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dfeM2mVta5Hb"
      },
      "outputs": [],
      "source": [
        "#############\n",
        "y[y==0]=-1 # or y=np.where(y==0, -1, y)\n",
        "###########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "M1g4Vb4za5Hb",
        "outputId": "282803b9-7ec7-4d54-97f5-534ed10c7817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
              "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Zj8C-cD_a5Hb"
      },
      "outputs": [],
      "source": [
        "### Inputs values\n",
        "Inputs = data.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMF4LKb_a5Hc",
        "outputId": "a492eca9-3db6-4ecc-fb8d-8e755eb55c54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "Inputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's remove the last 50 rows in the inputs data (they belong to the class 2)"
      ],
      "metadata": {
        "id": "VjV5d0ZX0vEp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "y3xruEHZa5Hc"
      },
      "outputs": [],
      "source": [
        "#### New Input\n",
        "X = Inputs[:100,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hDg4AQUza5Hd",
        "outputId": "3f5a8244-8999-44aa-8ccd-193a5440a01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:, 0], y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "RNrh-r0xEzPV",
        "outputId": "ec0be767-4c5d-4a85-f737-cfce5890928c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f337c4b1b50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combines the dataset and Shuffle them using numpy"
      ],
      "metadata": {
        "id": "V15p2I-D1P-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-2LXYdI4a5Hd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c970e1-6aaf-41f4-8dc5-d918ab137c12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5. ,  2.3,  3.3,  1. ,  1. ],\n",
              "       [ 5.8,  2.7,  4.1,  1. ,  1. ],\n",
              "       [ 4.6,  3.4,  1.4,  0.3, -1. ],\n",
              "       [ 5.6,  2.9,  3.6,  1.3,  1. ],\n",
              "       [ 5.7,  2.9,  4.2,  1.3,  1. ],\n",
              "       [ 6. ,  2.7,  5.1,  1.6,  1. ],\n",
              "       [ 5.1,  2.5,  3. ,  1.1,  1. ],\n",
              "       [ 4.4,  3.2,  1.3,  0.2, -1. ],\n",
              "       [ 5. ,  3. ,  1.6,  0.2, -1. ],\n",
              "       [ 5.7,  4.4,  1.5,  0.4, -1. ],\n",
              "       [ 6.7,  3. ,  5. ,  1.7,  1. ],\n",
              "       [ 4.9,  3.1,  1.5,  0.1, -1. ],\n",
              "       [ 6.1,  2.8,  4. ,  1.3,  1. ],\n",
              "       [ 6.2,  2.9,  4.3,  1.3,  1. ],\n",
              "       [ 4.9,  3.1,  1.5,  0.2, -1. ],\n",
              "       [ 6.6,  3. ,  4.4,  1.4,  1. ],\n",
              "       [ 5.8,  2.7,  3.9,  1.2,  1. ],\n",
              "       [ 5.1,  3.3,  1.7,  0.5, -1. ],\n",
              "       [ 5.2,  2.7,  3.9,  1.4,  1. ],\n",
              "       [ 4.8,  3. ,  1.4,  0.3, -1. ],\n",
              "       [ 6.1,  2.8,  4.7,  1.2,  1. ],\n",
              "       [ 4.8,  3. ,  1.4,  0.1, -1. ],\n",
              "       [ 4.4,  2.9,  1.4,  0.2, -1. ],\n",
              "       [ 5. ,  3.6,  1.4,  0.2, -1. ],\n",
              "       [ 5.7,  2.6,  3.5,  1. ,  1. ],\n",
              "       [ 6.7,  3.1,  4.7,  1.5,  1. ],\n",
              "       [ 5.1,  3.5,  1.4,  0.3, -1. ],\n",
              "       [ 6.7,  3.1,  4.4,  1.4,  1. ],\n",
              "       [ 4.6,  3.2,  1.4,  0.2, -1. ],\n",
              "       [ 7. ,  3.2,  4.7,  1.4,  1. ],\n",
              "       [ 4.8,  3.1,  1.6,  0.2, -1. ],\n",
              "       [ 5.4,  3.9,  1.7,  0.4, -1. ],\n",
              "       [ 4.3,  3. ,  1.1,  0.1, -1. ],\n",
              "       [ 5.4,  3.4,  1.5,  0.4, -1. ],\n",
              "       [ 5.6,  3. ,  4.1,  1.3,  1. ],\n",
              "       [ 4.8,  3.4,  1.6,  0.2, -1. ],\n",
              "       [ 6.6,  2.9,  4.6,  1.3,  1. ],\n",
              "       [ 6. ,  3.4,  4.5,  1.6,  1. ],\n",
              "       [ 5.2,  4.1,  1.5,  0.1, -1. ],\n",
              "       [ 5. ,  3.5,  1.3,  0.3, -1. ],\n",
              "       [ 5.4,  3.9,  1.3,  0.4, -1. ],\n",
              "       [ 5.2,  3.5,  1.5,  0.2, -1. ],\n",
              "       [ 5. ,  3.2,  1.2,  0.2, -1. ],\n",
              "       [ 5.5,  3.5,  1.3,  0.2, -1. ],\n",
              "       [ 5.8,  2.6,  4. ,  1.2,  1. ],\n",
              "       [ 5.5,  2.6,  4.4,  1.2,  1. ],\n",
              "       [ 6. ,  2.9,  4.5,  1.5,  1. ],\n",
              "       [ 6.8,  2.8,  4.8,  1.4,  1. ],\n",
              "       [ 6.2,  2.2,  4.5,  1.5,  1. ],\n",
              "       [ 5.1,  3.8,  1.6,  0.2, -1. ],\n",
              "       [ 5.5,  2.3,  4. ,  1.3,  1. ],\n",
              "       [ 5.9,  3.2,  4.8,  1.8,  1. ],\n",
              "       [ 5.5,  2.4,  3.8,  1.1,  1. ],\n",
              "       [ 5.9,  3. ,  4.2,  1.5,  1. ],\n",
              "       [ 5.7,  3.8,  1.7,  0.3, -1. ],\n",
              "       [ 6.1,  3. ,  4.6,  1.4,  1. ],\n",
              "       [ 4.9,  2.4,  3.3,  1. ,  1. ],\n",
              "       [ 5.7,  3. ,  4.2,  1.2,  1. ],\n",
              "       [ 6.5,  2.8,  4.6,  1.5,  1. ],\n",
              "       [ 5.7,  2.8,  4.5,  1.3,  1. ],\n",
              "       [ 5.2,  3.4,  1.4,  0.2, -1. ],\n",
              "       [ 6.9,  3.1,  4.9,  1.5,  1. ],\n",
              "       [ 5.4,  3. ,  4.5,  1.5,  1. ],\n",
              "       [ 5.5,  2.5,  4. ,  1.3,  1. ],\n",
              "       [ 5. ,  3.3,  1.4,  0.2, -1. ],\n",
              "       [ 6.3,  2.3,  4.4,  1.3,  1. ],\n",
              "       [ 4.9,  3.6,  1.4,  0.1, -1. ],\n",
              "       [ 5.3,  3.7,  1.5,  0.2, -1. ],\n",
              "       [ 5.5,  4.2,  1.4,  0.2, -1. ],\n",
              "       [ 5. ,  3.5,  1.6,  0.6, -1. ],\n",
              "       [ 5. ,  3.4,  1.5,  0.2, -1. ],\n",
              "       [ 6. ,  2.2,  4. ,  1. ,  1. ],\n",
              "       [ 5.7,  2.8,  4.1,  1.3,  1. ],\n",
              "       [ 4.7,  3.2,  1.6,  0.2, -1. ],\n",
              "       [ 5.6,  2.5,  3.9,  1.1,  1. ],\n",
              "       [ 6.4,  3.2,  4.5,  1.5,  1. ],\n",
              "       [ 4.9,  3. ,  1.4,  0.2, -1. ],\n",
              "       [ 5. ,  2. ,  3.5,  1. ,  1. ],\n",
              "       [ 6.1,  2.9,  4.7,  1.4,  1. ],\n",
              "       [ 4.7,  3.2,  1.3,  0.2, -1. ],\n",
              "       [ 5.6,  3. ,  4.5,  1.5,  1. ],\n",
              "       [ 4.6,  3.6,  1. ,  0.2, -1. ],\n",
              "       [ 5.5,  2.4,  3.7,  1. ,  1. ],\n",
              "       [ 5. ,  3.4,  1.6,  0.4, -1. ],\n",
              "       [ 5.8,  4. ,  1.2,  0.2, -1. ],\n",
              "       [ 5.1,  3.4,  1.5,  0.2, -1. ],\n",
              "       [ 5.1,  3.8,  1.9,  0.4, -1. ],\n",
              "       [ 5.4,  3.4,  1.7,  0.2, -1. ],\n",
              "       [ 4.4,  3. ,  1.3,  0.2, -1. ],\n",
              "       [ 5.6,  2.7,  4.2,  1.3,  1. ],\n",
              "       [ 5.4,  3.7,  1.5,  0.2, -1. ],\n",
              "       [ 4.5,  2.3,  1.3,  0.3, -1. ],\n",
              "       [ 6.4,  2.9,  4.3,  1.3,  1. ],\n",
              "       [ 5.1,  3.8,  1.5,  0.3, -1. ],\n",
              "       [ 5.1,  3.7,  1.5,  0.4, -1. ],\n",
              "       [ 5.1,  3.5,  1.4,  0.2, -1. ],\n",
              "       [ 6.3,  2.5,  4.9,  1.5,  1. ],\n",
              "       [ 6.3,  3.3,  4.7,  1.6,  1. ],\n",
              "       [ 4.6,  3.1,  1.5,  0.2, -1. ],\n",
              "       [ 4.8,  3.4,  1.9,  0.2, -1. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dataset=np.c_[X, y]\n",
        "np.random.seed(3)\n",
        "np.random.shuffle(dataset)\n",
        "dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data into (X_train, Y_train), (X_test, Y_test):  80% for training and 20% for test"
      ],
      "metadata": {
        "id": "mhbqMNIV3DrM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YTxsELH1a5He"
      },
      "outputs": [],
      "source": [
        "#########\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
        "#or \n",
        "# p=0.8 #percentage 80%\n",
        "# split=int(len(dataset)*p)\n",
        "# X_train=dataset[:split,:-1]\n",
        "# X_test=dataset[split:,:-1]\n",
        "# Y_train=dataset[:split, -1]\n",
        "# Y_test=dataset[split:,-1]\n",
        "###########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "f2SrQK0ra5He",
        "outputId": "fdae3e12-c1ac-4eeb-fdfa-29370cd72851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 4)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LQdFxmC4a5Hf",
        "outputId": "bb5b24eb-e21c-4490-b26a-867255fad87b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80,)\n",
            "(20, 4)\n",
            "(20,)\n"
          ]
        }
      ],
      "source": [
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement the class Perceptron\n",
        "\n",
        "$ŷ[i] = Θ^TX[i]$\n",
        "\n",
        "if  $y[i]*np.sign(ŷ[i]) <= 0$:\n",
        "\n",
        "        update Θ: Θ = Θ + y[i]*X[i]\n",
        "else:\n",
        "\n",
        "      Θ = Θ\n",
        "\n",
        "## For prediction: \n",
        "\n",
        "np.sign(X @ Θ)"
      ],
      "metadata": {
        "id": "-S45JTl04rf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rZ6z6emt3wUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "Fi4m35Q6a5Hh"
      },
      "outputs": [],
      "source": [
        "class perceptron:\n",
        "    \"\"\"class that implements the perceptron\"\"\"\n",
        "    eps = 1e-2\n",
        "    def __init__(self, X, Y,theta, iter_= 100):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.iter_ = iter_\n",
        "        self.theta = theta\n",
        "        #self.y_hat={}\n",
        "        \n",
        "    def train(self):\n",
        "        #loop over the number of iteration and the number of example\n",
        "        for epoch in range(self.iter_):\n",
        "          for i in range(self.X.shape[0]):            \n",
        "            self.y_hat=self.theta.T@self.X[i]\n",
        "            if self.Y[i]*np.sign(self.y_hat)<=0: self.theta=self.theta+self.Y[i]*self.X[i]\n",
        "            else:self.theta=self.theta\n",
        "        # compute the output of the model and update theta if necessary\n",
        "    \n",
        "    def predic(self,X):\n",
        "      return np.sign(X@self.theta)\n",
        "      \n",
        "    \n",
        "    def accuracy(self,X,Y):\n",
        "        return \"{} %\".format((np.sum(Y==self.predic(X))/X.shape[0])*100)\n",
        "        \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "wcwMg-Jga5Hi"
      },
      "outputs": [],
      "source": [
        "perceptron = perceptron(X_train,Y_train,np.random.rand(4)*1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "jZquZaUva5Hj"
      },
      "outputs": [],
      "source": [
        "perceptron.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "mrNV3LiUa5Hk",
        "outputId": "67eff267-066f-45bc-92e0-12e563b0c95d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
              "        1., -1.,  1., -1.,  1., -1., -1.])"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "perceptron.predic(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "M_CL5aBBa5Hk",
        "outputId": "f49dc291-7d64-494e-b1d0-4d9178652839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'100.0 %'"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "perceptron.accuracy(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9TxPjKOa5Hk",
        "outputId": "2c065409-987a-498e-83fc-9d6589c6bf1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#np.sum(Y_test==Perc.predic(X_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Gilda of Perceptron_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}